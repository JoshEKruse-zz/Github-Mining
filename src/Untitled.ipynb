{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "spam.data not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3f548993402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# read data from csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spam.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;31m# get size of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[0;32m   1742\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1744\u001b[1;33m             \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1745\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: spam.data not found."
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# function: calc_gradient\n",
    "# calculates the gradient for a specific weightVector\n",
    "# returns: the mean of the gradients as a vector\n",
    "def calc_gradient(weightVector, y_tild, X) :\n",
    "    size = y_tild.shape[0]\n",
    "\n",
    "    sum = 0\n",
    "    for index in range(size) :\n",
    "        sum += (-y_tild[index] * X[index]) / (1 + np.exp(y_tild[index] * weightVector * X[index]))\n",
    "    mean = sum / size\n",
    "\n",
    "    #m = X.shape[0]\n",
    "    #gradient =  (1 / m) * np.dot(X.T, (1 / (1 + np.exp(-(np.dot(X, weightVector))))) - y)\n",
    "\n",
    "    return mean\n",
    "\n",
    "# function: gradient_descent\n",
    "# calculates the gradient descent for a given X matrix with corresponding y vector\n",
    "def gradient_descent( X, y, stepSize, maxIterations) :\n",
    "\n",
    "    # declare weightVector which is initialized to the zero vector\n",
    "    #   one element for each feature\n",
    "    dimension = X.shape\n",
    "    features = dimension[1]\n",
    "    weightVector = np.zeros(features)\n",
    "\n",
    "    # declare weightMatrix of real number\n",
    "    #   number of rows = features, number of cols = maxIterations\n",
    "    num_of_entries = features * maxIterations\n",
    "    weightMatrix = np.array(np.zeros(num_of_entries).reshape(features, maxIterations))\n",
    "\n",
    "    size = y.shape[0]\n",
    "    y_tild = np.empty(size)\n",
    "    for index in range(size):\n",
    "        if (y[index] == 0): y_tild[index] = -1\n",
    "        else : y_tild[index] = 1\n",
    "\n",
    "    for index in range(maxIterations) :\n",
    "        # first compute the gradient given the current weightVector\n",
    "        #   make sure that the gradient is of the mean logistic loss over all training data\n",
    "        #print(weightVector)\n",
    "        gradient = calc_gradient(weightVector, y_tild, X)\n",
    "\n",
    "        # then update weightVector by taking a step in the negative gradient direction\n",
    "        weightVector = weightVector - stepSize * gradient\n",
    "\n",
    "        # then store the resulting weightVector in the corresponding column of weightMatrix\n",
    "        for row in range(features) :\n",
    "            weightMatrix[row][index] = weightVector[row]\n",
    "\n",
    "    return weightMatrix\n",
    "\n",
    "# read data from csv\n",
    "all_data = np.genfromtxt('spam.data', delimiter=\" \")\n",
    "# get size of data\n",
    "size = all_data.shape[1] - 1\n",
    "# set inputs to everything but last col, and scale\n",
    "X = scale(np.delete(all_data, size, axis=1))\n",
    "# set outputs to last col of data\n",
    "y = all_data[:, size]\n",
    "\n",
    "# Create train, test, and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# print sizes of each set\n",
    "print(\"{: >11} {: >4} {: >4}\".format(\"\", \"y\", \"\"))\n",
    "print(\"{: >11} {: >4} {: >4}\".format(\"set\", 0, 1))\n",
    "print(\"{: >11} {: >4} {: >4}\".format(\"train\", np.sum(y_train==0), np.sum(y_train==1)))\n",
    "print(\"{: >11} {: >4} {: >4}\".format(\"test\", np.sum(y_test==0), np.sum(y_test==1)))\n",
    "print(\"{: >11} {: >4} {: >4}\".format(\"validation\", np.sum(y_val==0), np.sum(y_val==1)))\n",
    "\n",
    "# get weightMatrix\n",
    "maxIterations = 500\n",
    "weightMatrix = gradient_descent(X_train, y_train, 0.2, maxIterations)\n",
    "\n",
    "# calculate predicted matrix, round each answer\n",
    "train_pred = np.around(np.dot( X_train, weightMatrix))\n",
    "val_pred = np.around(np.dot( X_val, weightMatrix))\n",
    "\n",
    "# calculate percent error\n",
    "train_result = []\n",
    "val_result = []\n",
    "for index in range(maxIterations) :\n",
    "    train_result.append( np.mean( y_train == train_pred[:,index]))\n",
    "for index in range(maxIterations):\n",
    "    val_result.append(np.mean( y_val == val_pred[:, index]))\n",
    "train_min_index, train_min_value = min(enumerate(train_result), key=operator.itemgetter(1))\n",
    "val_min_index, val_min_value = min(enumerate(val_result), key=operator.itemgetter(1))\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(train_result, \"g-\", label='train')\n",
    "ax.annotate('train min', xy=(train_min_index, train_min_value), xytext=(train_min_index, train_min_value-.1),\n",
    "            arrowprops=dict(facecolor='green', shrink=0.05),)\n",
    "line2, = ax.plot(val_result, \"r-\", label='validation')\n",
    "ax.annotate('validation min', xy=(val_min_index, val_min_value), xytext=(val_min_index, val_min_value+.1),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),)\n",
    "ax.set_ylabel(\"Percent\")\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_title(\"Percent Error\")\n",
    "ax.set_ylim(0,.8)\n",
    "ax.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# calculate logistic loss\n",
    "train_results = []\n",
    "for index in range(maxIterations) :\n",
    "    train_results.append( sklearn.metrics.log_loss( y_train, train_pred[:,index]) )\n",
    "val_results = []\n",
    "for index in range(maxIterations):\n",
    "    val_results.append(sklearn.metrics.log_loss( y_val, val_pred[:, index]))\n",
    "train_min = min(train_result)\n",
    "val_min = min(val_result)\n",
    "train_min_index, train_min_value = min(enumerate(train_result), key=operator.itemgetter(1))\n",
    "val_min_index, val_min_value = min(enumerate(val_result), key=operator.itemgetter(1))\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(train_result, \"g-\", label='train')\n",
    "ax.annotate('train min', xy=(train_min_index, train_min_value), xytext=(train_min_index, train_min_value-.1),\n",
    "            arrowprops=dict(facecolor='green', shrink=0.05),)\n",
    "line2, = ax.plot(val_result, \"r-\", label='validation')\n",
    "ax.annotate('validation min', xy=(val_min_index, val_min_value), xytext=(val_min_index, val_min_value+.1),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),)\n",
    "\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_title(\"Logistic Loss\")\n",
    "ax.set_ylim(0,.8)\n",
    "ax.legend()\n",
    "pyplot.show()\n",
    "\n",
    "print(weightMatrix[:,val_min_index])\n",
    "\n",
    "# create log reg table of errors\n",
    "print(\"{: >11} {: >9} {: >9}\".format(\"\", \"log reg\", \"baseline\"))\n",
    "print(\"{: >11} {: >9} {: >9}\".format(\"train\",\"\",\"\"))\n",
    "print(\"{: >11} {: >9} {: >9}\".format(\"validation\",\"\",\"\"))\n",
    "print(\"{: >11} {: >9} {: >9}\".format(\"test\", \"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
